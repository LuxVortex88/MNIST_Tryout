{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwjK5pe+tM3u6foeu0SPk+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k4CdWS78LhNc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset with normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Download and Load the training data\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle= False)"
      ],
      "metadata": {
        "id": "QLAUid7jf07n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71f7943-7eb5-4706-8672-9c0cff967454"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 52.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.72MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.58MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple feedforward neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "       super(SimpleNet, self).__init__()\n",
        "       self.fc1 = nn.Linear(28*28, 128)\n",
        "       self.relu = nn.ReLU()\n",
        "       self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 28 * 28) # Flatten the image\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "1uDx7oZtOlVG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model instance\n",
        "model = SimpleNet()\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "5WkdO14Q4rDU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model for 5 epochs\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1VDliIyFRPe",
        "outputId": "5ef7ceec-cbd6-4125-b9eb-f0c213e4a8ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7540\n",
            "Epoch 2, Loss: 0.3659\n",
            "Epoch 3, Loss: 0.3214\n",
            "Epoch 4, Loss: 0.2966\n",
            "Epoch 5, Loss: 0.2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate and print classification report\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "from sklearn.metrics import classification_report\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate and print classification report\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      all_preds.extend(predicted.numpy())\n",
        "      all_labels.extend(labels.numpy())\n",
        "print(classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiQa8jTllZ8Q",
        "outputId": "0a851bea-ea0f-4f36-a6c5-d40073e1e1be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.95      0.98      0.97      1135\n",
            "           2       0.95      0.88      0.91      1032\n",
            "           3       0.90      0.92      0.91      1010\n",
            "           4       0.89      0.96      0.92       982\n",
            "           5       0.94      0.86      0.89       892\n",
            "           6       0.91      0.96      0.94       958\n",
            "           7       0.93      0.93      0.93      1028\n",
            "           8       0.90      0.88      0.89       974\n",
            "           9       0.94      0.89      0.91      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.93      0.92      0.92     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), \"mnist_model.pth\")\n",
        "print(\"Model saved as mnist_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdAan1F_nb_3",
        "outputId": "bddec07b-401c-4dad-ff0e-2fefcce5e5e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as mnist_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy & Loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize lists to store metrics during training\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Train the model for 5 epochs\n",
        "for epoch in range(5):\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "    train_accuracies.append(100 * correct / total)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "    # You'll need to add validation loop and calculate val_losses, val_accuracies here\n",
        "\n",
        "# Handle unequal lengths or missing data gracefully\n",
        "num_epochs = min(len(train_losses), len(val_losses), len(train_accuracies))\n",
        "\n",
        "# Now you can proceed with plotting using train_losses, val_losses, train_accuracies, val_accuracies# Load model\n",
        "model = SimpleNet()\n",
        "model.load_state_dict(torch.load(\"mnist_model.pth\"))\n",
        "model.eval()\n",
        "print(\"Model loaded and ready for inference\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fa-35CEn4V6",
        "outputId": "e9ef6bb1-3127-4594-8753-f7a28eb5fd2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2656, Accuracy: 92.27%\n",
            "Epoch 2, Loss: 0.2657, Accuracy: 92.27%\n",
            "Epoch 3, Loss: 0.2656, Accuracy: 92.27%\n",
            "Epoch 4, Loss: 0.2655, Accuracy: 92.27%\n",
            "Epoch 5, Loss: 0.2656, Accuracy: 92.27%\n",
            "Model loaded and ready for inference\n"
          ]
        }
      ]
    }
  ]
}